{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1127a19-7e08-492e-ad90-7951b065de55",
   "metadata": {},
   "source": [
    "# Online-NST, Алгоритм Гатиса"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3780ff5e-0c9e-4194-a835-a3e8e001fa30",
   "metadata": {},
   "source": [
    "# Содержание\n",
    "## 1. [Свёрточная нейросеть для извлечения признаков](#section1)\n",
    "## 2. [Слои лоссов](#section2)\n",
    "## 3. [Слой нормализации](#section3)\n",
    "## 4. [Класс модели переноса стиля](#section4)\n",
    "## 5. [Тестирование бейзлайн решения](#section5)\n",
    "- ### [5.1. Загрузка тестовых данных](#section5.1)\n",
    "- ### [5.2. Функция эксперимента](#section5.2)\n",
    "- ### [5.3. Запуск бейзлайн решения. Оценка и сохранение результатов](#section5.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1189f4cd-4d55-4e42-a20e-2911c98da86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d022d39e-b699-4396-8035-aac692efbbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, ToPILImage\n",
    "from torchvision.models import vgg19\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d852e501-695a-45b9-9ab9-35b319778669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.set_default_device(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa287679-7339-4c2d-bfe2-b1e4cb8cb224",
   "metadata": {},
   "source": [
    "## <a id=\"section1\"> </a> 1. Свёрточная нейросеть для извлечения признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a610bac-edf6-4e0b-8da9-07e794cdad95",
   "metadata": {},
   "source": [
    "Возьмём первые 11 слоев предобученной VGG19, среди которых 5 свёрток, и заморозим их, так как оптимизировать их параметры мы не собираемся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7df901aa-4f6d-48fb-b19d-6ea51515316a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): ReLU(inplace=True)\n",
       "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (6): ReLU(inplace=True)\n",
       "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): ReLU(inplace=True)\n",
       "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_cnn = vgg19(pretrained=True).features[0 : 11].to(device)\n",
    "\n",
    "for param in base_cnn.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "base_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccc8e75-7404-4091-b20f-ece2c83c65bc",
   "metadata": {},
   "source": [
    "## <a id=\"section2\"> </a> 2. Слои лоссов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f03b08-29e0-42af-ae5c-68ca2d3baa70",
   "metadata": {},
   "source": [
    "Для рассчёта функции потерь добавим слои для потери контента и потери стиля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3fc28d7-1db6-4183-9bbc-732412cfeff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentLoss(nn.Module):\n",
    "    def __init__(self, target):\n",
    "        super(ContentLoss, self).__init__()\n",
    "        self.target = target.detach().to(device)\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        self.loss = F.mse_loss(inp, self.target).to(device)\n",
    "        return inp\n",
    "    \n",
    "\n",
    "class StyleLoss(nn.Module):\n",
    "    def __init__(self, target):\n",
    "        super(StyleLoss, self).__init__()\n",
    "        self.target = StyleLoss.gram_matrix(target).detach().to(device)\n",
    "        \n",
    "    @staticmethod\n",
    "    def gram_matrix(inp):\n",
    "        batch_size, nmaps, w, h = inp.size()\n",
    "    \n",
    "        features = inp.view(batch_size * nmaps, w * h) # Получаем для каждой карты признаков вектор размера wxh\n",
    "    \n",
    "        G = torch.mm(features, features.T)\n",
    "    \n",
    "        return G.div(batch_size * nmaps * w * h)\n",
    "\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        G = StyleLoss.gram_matrix(inp).to(device)\n",
    "        self.loss = F.mse_loss(G, self.target).to(device)\n",
    "        return inp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73425c8-268d-4ceb-9836-52cca7313f58",
   "metadata": {},
   "source": [
    "## <a id=\"section3\"> </a> 3. Слой нормализации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9360cc3-2659-4321-847f-efde978a7dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG обучалась на картинках с определенными средним значением и средним стандратным отклонением.\n",
    "# Поэтому нужно приводить свои изображение к примерно такому же распределению.\n",
    "\n",
    "VGG19_NORMALIZATION_MEAN = torch.tensor([0.485, 0.456, 0.406])\n",
    "VGG19_NORMALIZATION_STD = torch.tensor([0.229, 0.224, 0.225])\n",
    "\n",
    "class Normalization(nn.Module):\n",
    "    def __init__(self, mean=VGG19_NORMALIZATION_MEAN,\n",
    "                 std=VGG19_NORMALIZATION_STD):\n",
    "       super(Normalization, self).__init__()\n",
    "       self.mean = torch.tensor(mean).view(-1, 1, 1)\n",
    "       self.std = torch.tensor(std).view(-1, 1, 1)\n",
    "   \n",
    "    def forward(self, img):\n",
    "       return (img - self.mean) / self.std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83343fd9-3938-46ea-8ce1-c581ca50191c",
   "metadata": {},
   "source": [
    "## <a id=\"section4\"> </a> 4. Функция-конструктор модели переноса стиля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5666015c-6498-47ef-8cc5-a5ef0f6d7a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTENT_LAYERS_DEFAULT = ['Conv_4']\n",
    "STYLE_LAYERS_DEFAULT = ['Conv_1', 'Conv_2', 'Conv_3', 'Conv_4', 'Conv_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a4ce9d4-501e-4702-a339-a847e05894d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleModel:\n",
    "    \"\"\"\n",
    "    Класс модели переноса стиля\n",
    "    \"\"\"\n",
    "    def __init__(self, base_cnn, content_img, style_img, normalization_mean, normalization_std, content_layers, style_layers):\n",
    "        content_img = content_img.to(device)\n",
    "        style_img = style_img.to(device)\n",
    "        self.model = nn.Sequential().to(device)\n",
    "        self.content_losses = []\n",
    "        self.style_losses = []\n",
    "        \n",
    "        self.model.add_module(\"ImageNorm\", Normalization(mean=normalization_mean, std=normalization_std).to(device))\n",
    "\n",
    "        conv_counter: int = 0\n",
    "        module_name: str = \"\"\n",
    "        \n",
    "        for layer in base_cnn.children():\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                conv_counter += 1\n",
    "                module_name = f\"Conv_{conv_counter}\"\n",
    "                \n",
    "            elif isinstance(layer, nn.ReLU):\n",
    "                module_name = f\"ReLU_{conv_counter}\"\n",
    "                layer = nn.ReLU(inplace=False)\n",
    "                \n",
    "            elif isinstance(layer, nn.MaxPool2d):\n",
    "                module_name = f\"MaxPool2d_{conv_counter}\"\n",
    "            \n",
    "            else:\n",
    "                raise ValueError\n",
    "            \n",
    "            self.model.add_module(module_name, layer.to(device))\n",
    "\n",
    "            if module_name in content_layers:\n",
    "                target = self.model(content_img).detach().to(device)\n",
    "                content_loss_module = ContentLoss(target)\n",
    "                self.content_losses.append(content_loss_module)\n",
    "                self.model.add_module(f\"ContentLoss_{conv_counter}\", content_loss_module)\n",
    "                \n",
    "            if module_name in style_layers:\n",
    "                target = self.model(style_img).detach().to(device)\n",
    "                style_loss_module = StyleLoss(target)\n",
    "                self.style_losses.append(style_loss_module)\n",
    "                self.model.add_module(f\"StyleLoss_{conv_counter}\", style_loss_module)\n",
    "                \n",
    "        self.model.to(device)\n",
    "\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}(model = {self.model})'\n",
    "\n",
    "\n",
    "    def transfer_style(self, input_image, num_steps=300, style_weight=10000, content_weight=1, print_logs=False):\n",
    "        input_image = input_image.to(device)\n",
    "        \n",
    "        input_image.requires_grad = True\n",
    "        self.model.eval()\n",
    "        \n",
    "        optimizer = optim.Adam([input_image], lr=0.05)\n",
    "\n",
    "        for i in range(num_steps):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            self.model(input_image)\n",
    "            content_final_loss = 0.0\n",
    "            style_final_loss = 0.0\n",
    "            \n",
    "            for content_loss in self.content_losses:\n",
    "                content_final_loss += content_loss.loss\n",
    "\n",
    "            for style_loss in self.style_losses:\n",
    "                style_final_loss += style_loss.loss\n",
    "\n",
    "            loss = content_weight * content_final_loss + style_weight * style_final_loss\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                input_image.clamp_(0, 1)\n",
    "\n",
    "            if print_logs:\n",
    "                if i % 10 == 0:\n",
    "                    print(f\"Эпоха номер {i + 1}\")\n",
    "                    print(f\"content_epoch_loss: {content_final_loss}\")\n",
    "                    print(f\"style_epoch_loss: {style_final_loss}\")\n",
    "                    print(f\"final_epoch_loss: {loss}\")\n",
    "                    plt.imshow(ToPILImage()(input_image[0]))\n",
    "                    plt.show()\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            input_image.clamp_(0, 1)\n",
    "            \n",
    "        return input_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f918b5c2-68a4-453a-9381-4725391819af",
   "metadata": {},
   "source": [
    "## <a id=\"section5\"> </a>5. Тестирование бейзлайн решения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaa1fe4-9085-485d-a54c-a19c75ed53e6",
   "metadata": {},
   "source": [
    "### <a id=\"section5.1\"> </a> 5.1. Загрузка тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f72d25a-0852-4de1-b04e-a0b54250797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "IMSIZE = (256, 256)\n",
    "\n",
    "contents_directory = \"../data/contents/\"\n",
    "styles_directory = \"../data/styles/\"\n",
    "\n",
    "content_names = os.listdir(contents_directory) \n",
    "style_names = os.listdir(styles_directory)\n",
    "\n",
    "content_images = [Image.open(contents_directory + filename).resize(IMSIZE) for filename in content_names]\n",
    "style_images = [Image.open(styles_directory + filename).resize(IMSIZE) for filename in style_names]\n",
    "\n",
    "random.shuffle(content_images)\n",
    "random.shuffle(style_images)\n",
    "\n",
    "content_images = content_images[:8]\n",
    "style_images = style_images[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eed7cb-82c0-4757-b183-881afea58800",
   "metadata": {},
   "source": [
    "### <a id=\"section5.2\"> </a> 5.2. Функция эксперимента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dabff25-9d5b-4f67-b8e8-161f5a503e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7a8c14e-7da0-4ebd-a909-393a9524002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(base_model, content_images, style_images, \n",
    "               optimizer, lr, num_steps,\n",
    "               scheduler_step, gamma,\n",
    "               content_weight, style_weight, \n",
    "               content_layers, style_layers, \n",
    "               noisy_input: bool = False, print_logs: int|None=None) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        * base_model - слои свёрточной NN\n",
    "        * content_images - список изображений PIL.Image\n",
    "        * style_images - список стилей PIL.Image\n",
    "        * scheduler_step - число, через какое количество эпох менять lr\n",
    "        * gamma - число, на которое lr умножается раз scheduler_step эпох\n",
    "        * content_weight, style_weight - веса потерь контента и стиля\n",
    "        * content_layers, style_layers - слои, после которых вставляются слои лоссов\n",
    "        * noisy_input - True/False, инициализировать выходное изображение шумом (True) или как копию content_image (False)\n",
    "    \"\"\"\n",
    "    results: dict[str, float] = {\n",
    "        \"avg_time\": 0.0, \n",
    "        \"content_score\": 0.0,\n",
    "        \"style_score\": 0.0\n",
    "    }\n",
    "    \n",
    "    iteration_counter = 0\n",
    "    total_time_spent_on_transfering = 0.0\n",
    "\n",
    "    total_content_score = 0.0\n",
    "    total_style_score = 0.0\n",
    "    \n",
    "    for content_img in content_images:\n",
    "        for style_img in style_images:\n",
    "            \n",
    "            start = time.time()\n",
    "            \n",
    "            content = ToTensor()(content_img)[:3].unsqueeze(0)\n",
    "            style = ToTensor()(style_img)[:3].unsqueeze(0)\n",
    "        \n",
    "            input_ = torch.randn(content.data.size()) if noisy_input else content.clone()\n",
    "            \n",
    "            style_model = StyleModel(\n",
    "                base_cnn=base_model,\n",
    "                content_img=content,\n",
    "                style_img=style,\n",
    "                content_layers=content_layers,\n",
    "                style_layers=style_layers\n",
    "            )\n",
    "\n",
    "            output = style_model.transfer_style(\n",
    "                input_image=input_,\n",
    "                optimizer_class=optimizer,\n",
    "                lr=lr,\n",
    "                num_steps=num_steps,\n",
    "                scheduler_step=scheduler_step,\n",
    "                gamma=gamma,\n",
    "                content_weight=content_weight,\n",
    "                style_weight=style_weight,\n",
    "                print_logs=print_logs\n",
    "            )\n",
    "            \n",
    "            end = time.time()\n",
    "            total_time_spent_on_transfering += end - start\n",
    "            iteration_counter += 1\n",
    "\n",
    "            with torch.no_grad():\n",
    "                total_content_score += F.mse_loss(output.to(device), content.to(device)).item()\n",
    "                style_loss = StyleLoss(style)\n",
    "                style_loss(output)\n",
    "                total_style_score += style_loss.loss.item()\n",
    "\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(13, 16))\n",
    "            axes[0].set_title(\"Content\")\n",
    "            axes[1].set_title(\"Style\")\n",
    "            axes[2].set_title(\"Result\")\n",
    "            axes[0].imshow(content_img)\n",
    "            axes[1].imshow(style_img)\n",
    "            axes[2].imshow(ToPILImage()(output[0]))\n",
    "            plt.show()\n",
    "            \n",
    "    results[\"avg_time\"] = total_time_spent_on_transfering / iteration_counter\n",
    "    results[\"content_score\"] = total_content_score / iteration_counter\n",
    "    results[\"style_score\"] = total_style_score / iteration_counter\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a625417c-82d9-43e8-80e7-e5a6cc50c8dd",
   "metadata": {},
   "source": [
    "### <a id=\"section5.3\"> </a> 5.3. Запуск бейзлайн решения. Оценка и сохранение результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61e549dc-d015-44aa-9ea1-55d7d5dc7e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d234d77-99f6-4032-98cc-7de57629302b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/maksim/Repos/style-transfer/materials/online-nst/experiments/mlruns/409642611399561252', creation_time=1742381944787, experiment_id='409642611399561252', last_update_time=1742381944787, lifecycle_stage='active', name='Online-NST Baseline', tags={}>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ONLINE_NST_MLFLOW = \"/home/maksim/Repos/style-transfer/materials/online-nst/experiments/mlruns/\"\n",
    "\n",
    "mlflow.set_tracking_uri(ONLINE_NST_MLFLOW)\n",
    "mlflow.set_experiment(\"Online-NST Baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af5b2e1-0627-4e11-a9d5-3ca21ff28043",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    OPTIMIZER = optim.Adam\n",
    "    LR = 0.05\n",
    "    NUM_STEPS=400\n",
    "    CONTENT_WEIGHT = 1\n",
    "    STYLE_WEIGHT = 10**8\n",
    "    SCHEDULER_STEP = None\n",
    "    GAMMA=0.5\n",
    "    CONTENT_LAYERS = ['Conv_4']\n",
    "    STYLE_LAYERS = [f'Conv_{i}' for i in range(1, 6)]\n",
    "    \n",
    "    params = {\n",
    "        \"VGG-19_layers\": 11,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"lr\": LR,\n",
    "        \"num_steps\": NUM_STEPS,\n",
    "        \"content_weight\": CONTENT_WEIGHT,\n",
    "        \"style_weight\": STYLE_WEIGHT,\n",
    "        \"scheduler_step\": \"None\",\n",
    "        \"scheduler_gamma\": \"None\",\n",
    "        \"content_layers\": CONTENT_LAYERS,\n",
    "        \"style_layers\": STYLE_LAYERS\n",
    "    }\n",
    "\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    results = experiment(\n",
    "        base_model=base_cnn,\n",
    "        content_images=content_images,\n",
    "        style_images=style_images,\n",
    "        optimizer=OPTIMIZER,\n",
    "        lr=LR,\n",
    "        num_steps=NUM_STEPS,\n",
    "        scheduler_step=SCHEDULER_STEP,\n",
    "        gamma=GAMMA,\n",
    "        content_weight=CONTENT_WEIGHT,\n",
    "        style_weight=STYLE_WEIGHT,\n",
    "        content_layers=CONTENT_LAYERS,\n",
    "        style_layers=STYLE_LAYERS,\n",
    "        noisy_input=False,\n",
    "        print_logs=None\n",
    "    )\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6835039,
     "sourceId": 10982636,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6835144,
     "sourceId": 10982763,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6837026,
     "sourceId": 10985232,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
