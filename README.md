# Стилизация изображений
### Содержание
1. [Описание](#title1)
2. [Структура проекта](#title2)
3. [Технологии](#title3)
4. [Результаты](#title4)
    - 4.1. [Алгоритм Гатиса](#title4.1)
    - 4.2. [AdaIN-стилизатор](#title4.2)
    - 4.3. [Телеграм-бот](#title4.3)
5. [Установка и запуск проекта](#title5)
   

## <a id="title1">1.Описание.</a>
Проект состоит из двух частей:
1. Изучение и имплементация основных подходов к решению задачи NST(neural style transfer). Задача - переносить __произвольный__ стиль с одного изображенеия на другое.
2. Разработка телеграм-бота, предоставляющего удобный пользовательский интерфейс для стилизации изображений. 

В рамках первой части проекта сначала были выделены два наиболее популярных подхода:
* Алгоритм Гатиса: https://arxiv.org/pdf/1508.06576
* AdaIN-блок для решения задачи стилизации: https://arxiv.org/pdf/1703.06868

Затем были сформулированы конкретные задачи:
1. Имплементация приведённых выше статей в удобочитаемых ноутбуках с подробным разбором и комментариями.
2. Проведение экспериментов с параметрами алгоритма Гатиса с целью минимизации времени получения стилизации.
3. Обучение архитектуры с AdaIN-блоком.
4. Сравнение полученных решений и последующее их встраивание в телеграм-бота.
   
> [!IMPORTANT]
> Пункт 2 из списка выше имеет __критически важное__ значение, поскольку скорость создания стилизации напрямую влияет на восприятие пользователя.



## <a id="title2">2.Структура проекта.</a>
```
root/
├── tg-bot/          # Телеграм-бот
└── materials/       # Ноутбуки и .md-файлы с разбором основных методов стилизации изображений
    ├── online-nst/  # Разбор и имплементация алгоритма Гатиса
    ├── adain/       # Разбор, имплементация и обучение архитектуры, основанной на AdaIN-блоке
    ├── test-data/   # Тестовые картинки для оценки качества  
```



## <a id="title3">3.Технологии.</a>
### Tg-bot
* aiogram
* Redis - хранилище для FSM; брокер сообщений;
* Celery - очередь задач для выполнения стилизации в отдельном потоке;
### Ml-stack
* torch, torchvision
* MLflow (логгирование экспериментов)



## <a id="title4">4.Обзор результатов.</a>
### <a id="title4.1">4.1. Алгоритм Гатиса.</a>
#### Бейзлайн
Ознакомиться с реализацией алгоритма Гатиса с подробными комментариями можно в ноутбуке: `./materials/online-nst/gatys_baseline.ipynb`

Для бейзлайна были взяты следующие значения гиперпараметров оптимизации:
| Параметр               | Значение |
| ---------------------- | -------- |
| Количество слоев VGG19 | 11       |
| Оптимизатор            | Adam     |
| Learning rate          | 0.05     |
| Количество итераций    | 300      |
| Scheduler              | -        |
| Gamma                  | -        |
| Размер изображений     | 256      |

В процессе тестирования было измерено среднее время получения стилизации и средние значения потерь контента и стиля:

| Среднее время стилизации (CPU), c | Content Loss | Style Loss |
| --------------------------------- | ------------ | ---------- |
| 69.6634                           | 0.041467     | 0.002046   |

Были получены неплохие стилизации:
<img src="./report-imgs/gatys/baseline_ex1.png" alt="gatys1" width="45%"/> <img src="./report-imgs/gatys/baseline_ex2.png" alt="gatys2" width="45%"/>
<img src="./report-imgs/gatys/baseline_ex3.png" alt="gatys3" width="45%"/>

#### Влияние количества слоёв на качество стилизации
`./materials/online-nst/`
#### Минимизация времени стилизации

#### Выбор степени стилизации



### <a id="title4.2">4.2. AdaIN-стилизатор.</a>
Имплементация статьи https://arxiv.org/pdf/1703.06868 находится в ноутбуке `./materials/adain/adain_style_transfer.ipynb`.

Для обучения модели были взяты следующие датасеты:
* MsCoco - изображения контента (https://www.kaggle.com/datasets/hariwh0/ms-coco-dataset)
* Wiki-art - изображения стилей (https://www.kaggle.com/datasets/steubk/wikiart)

#### Первая попытка обучения
На текущий момент была предпринята одна попытка обучения реализованной архитектуры. Модель обучалась в течение 6 эпох на GPU (что заняло приблизительно 12 часов) на платформе Kaggle со следующими параметрами обучения:
* Оптимизатор: Adam
* LearningRate = 0.001
* Каждые 100 итераций LR умножался на 0.9995

Добиться удовлетворительного результата не удалось, декодер модели научился восстанавливать контуры исходного изображения, однако с переносом стиля модель не справилась. Выходные изображения получаются однотипными, размытыми, с отсутствием стиля:

<img src="./report-imgs/adain/adain_bad_bee.jpg" alt="Неудача1" width="45%"/> <img src="./report-imgs/adain/adain_bad_me.jpg" alt="Неудача2" width="45%"/>

__Анализ и дальнейшие шаги:__ изменение лоссов и выход нейросети говорят о недообучении модели, она не смогла сойтись к минимуму лосс-функции. Скорее всего, это результат достаточно большого значения learning_rate = 0.001 и редкого его уменьшения(каждые 100 итераций). Поэтому первое решение проблемы - уменьшение learning_rate. 




## <a id="title4">5. Установка и запуск проекта</a>
Will be soon...
